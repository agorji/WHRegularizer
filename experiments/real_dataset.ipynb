{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93e5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "import collections\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import ModelTrainer\n",
    "from datasets import avGFPDataset, GB1Dataset, SGEMMDataset, EntacmaeaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9c40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, n, multiplier=2, batch_norm=False):\n",
    "        super(FCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(n, multiplier*n)\n",
    "        self.fc2 = nn.Linear(multiplier*n, multiplier*n)\n",
    "        self.fc3 = nn.Linear(multiplier*n, n)\n",
    "        self.fc4 = nn.Linear(n, 1)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc4.weight)\n",
    "        \n",
    "        self.batch_norm = batch_norm\n",
    "        if self.batch_norm:\n",
    "            self.bn1 = nn.BatchNorm1d(multiplier*n)\n",
    "            self.bn2 = nn.BatchNorm1d(multiplier*n)\n",
    "            self.bn3 = nn.BatchNorm1d(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_norm:\n",
    "            x = self.bn1(F.leaky_relu(self.fc1(x)))\n",
    "            x = self.bn2(F.leaky_relu(self.fc2(x)))\n",
    "            x = self.bn3(F.leaky_relu(self.fc3(x)))\n",
    "            x = self.fc4(x)\n",
    "        else:\n",
    "            x = F.leaky_relu(self.fc1(x))\n",
    "            x = F.leaky_relu(self.fc2(x))\n",
    "            x = F.leaky_relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "\n",
    "        return x.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc3dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from cache.\n",
      "Fourier quality:\tSample R2:0.856\tTrain R2:0.773\n",
      "#0 - Train Loss: 0.680, R2: -0.111\tValidation Loss: 0.951, R2: 0.049\talternate_loss: 0.04168\n",
      "Fourier quality:\tSample R2:0.906\tTrain R2:0.880\n",
      "#1 - Train Loss: 0.492, R2: 0.196\tValidation Loss: 0.974, R2: 0.026\talternate_loss: 0.04104\n",
      "Fourier quality:\tSample R2:0.925\tTrain R2:0.892\n",
      "#2 - Train Loss: 0.417, R2: 0.320\tValidation Loss: 0.882, R2: 0.118\talternate_loss: 0.02894\n",
      "Fourier quality:\tSample R2:0.942\tTrain R2:0.866\n"
     ]
    }
   ],
   "source": [
    "fix_seed = 1\n",
    "random_seed = 11\n",
    "dataset = \"SGEMM\"\n",
    "\n",
    "train_size = 40\n",
    "\n",
    "config = {\n",
    "    \"training_method\": \"hashing\",\n",
    "    \"b\": 10,\n",
    "    \"lr\": 0.01, \n",
    "    \"weight_decay\": 0, \n",
    "    \"hadamard_lambda\": 0.0001,\n",
    "    \"num_epochs\": 50,\n",
    "    \"random_seed\": random_seed,\n",
    "    \"fix_seed\": fix_seed,\n",
    "    \"train_size\": train_size,\n",
    "    \"dataset\": dataset,\n",
    "    \"batch_size\": 16,\n",
    "    \"normalize\": True,\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"training_method\": \"normal\",\n",
    "    \"lr\": 0.01, \n",
    "    \"weight_decay\": 0, \n",
    "    \"num_epochs\": 100,\n",
    "    \"random_seed\": random_seed,\n",
    "    \"fix_seed\": fix_seed,\n",
    "    \"train_size\": train_size,\n",
    "    \"batch_size\": 16,\n",
    "    \"dataset\": dataset,\n",
    "    \"normalize\": True\n",
    "}\n",
    "\n",
    "# config = {\n",
    "#     \"training_method\": \"EN-S\",\n",
    "#     \"SPRIGHT_d\": 3,\n",
    "#     \"rho\": 0.01,\n",
    "#     \"b\": 7,\n",
    "#     \"lr\": 0.01, \n",
    "#     \"weight_decay\": 0, \n",
    "#     \"hadamard_lambda\": 1,\n",
    "#     \"num_epochs\": 100,\n",
    "#     \"random_seed\": random_seed,\n",
    "#     \"fix_seed\": fix_seed,\n",
    "#     \"train_size\": train_size,\n",
    "#     \"batch_size\": 16,\n",
    "#     \"dataset\": dataset,\n",
    "#     \"normalize\": True\n",
    "# }\n",
    "\n",
    "config = {\n",
    "    \"training_method\": \"alternate\",\n",
    "    \"b\": 10,\n",
    "    \"lr\": 0.01, \n",
    "    \"SPRIGHT_d\": 3,\n",
    "    \"weight_decay\": 0, \n",
    "    \"hadamard_lambda\": 0.01,\n",
    "    \"num_epochs\": 100,\n",
    "    \"random_seed\": random_seed,\n",
    "    \"fix_seed\": fix_seed,\n",
    "    \"train_size\": train_size,\n",
    "    \"dataset\": dataset,\n",
    "    \"batch_size\": 16,\n",
    "    \"normalize\": True,\n",
    "    \"intense_regularization\": True,\n",
    "    \"fourier_method\": \"swht\",\n",
    "    \"fourier_d\": 14,\n",
    "    \"warmup_epochs\": 0,\n",
    "}\n",
    "\n",
    "    \n",
    "# Dataset\n",
    "torch.manual_seed(config[\"fix_seed\"])\n",
    "if dataset == \"GB1\":\n",
    "    dataset = GB1Dataset()\n",
    "elif dataset == \"avGFP\":\n",
    "    dataset = avGFPDataset()\n",
    "elif dataset == \"SGEMM\":\n",
    "    dataset = SGEMMDataset()\n",
    "elif dataset == \"Entacmaea\":\n",
    "    dataset = EntacmaeaDataset()\n",
    "else:\n",
    "    raise Exception\n",
    "    \n",
    "if config.get(\"normalize\", False):\n",
    "    dataset.y = (dataset.y-torch.mean(dataset.y))/torch.std(dataset.y)\n",
    "dataset_size = len(dataset)\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [config[\"train_size\"], dataset_size - config[\"train_size\"]])\n",
    "\n",
    "# Train model\n",
    "torch.manual_seed(config[\"random_seed\"]) # Seed for network initialization\n",
    "in_dim = dataset.X.shape[1]\n",
    "model = FCN(in_dim, 1, batch_norm=False)\n",
    "trainer = ModelTrainer(model, train_ds, val_ds, config=config,  plot_results=True, checkpoint_cache=True)\n",
    "model = trainer.train_model()\n",
    "print(max([l[\"val_r2\"] for l in trainer.logs]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss(reduction='sum')\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6965041",
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.abs(input - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(torch.abs(input - target), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc073f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
